#!/usr/bin/env python
from __future__ import print_function

import sys
import cProfile
import inspect
import math
import mmap
import optparse
import os
import platform
import re
import socket
import subprocess
import struct
import threading
import time
import traceback
import warnings
from pathlib import Path

from core.addr import inet_ntoa6, addr_port
from core.attribdict import AttribDict
from core.common import (check_connection, check_sudo, check_whitelisted, get_ex_message, 
                         get_text, is_local, load_trails, patch_parser)
from core.compat import xrange
from core.datatype import LRUDict
from core.enums import BLOCK_MARKER, CACHE_TYPE, PROTO, TRAIL
from core.log import create_log_directory, flush_condensed_events, get_error_log_handle, log_error, log_event
from core.parallel import worker, write_block
from core.settings import (config, CAPTURE_TIMEOUT, CHECK_CONNECTION_MAX_RETRIES, CONFIG_FILE, CONSONANTS,
                           DLT_OFFSETS, DNS_EXHAUSTION_THRESHOLD, GENERIC_SINKHOLE_REGEX, HOMEPAGE, HOURLY_SECS,
                           HTTP_TIME_FORMAT, IGNORE_DNS_QUERY_SUFFIXES, IPPROTO_LUT, IS_WIN, LOCALHOST_IP,
                           LOCAL_SUBDOMAIN_LOOKUPS, MAX_CACHE_ENTRIES, MMAP_ZFILL_CHUNK_LENGTH, NAME,
                           NO_SUCH_NAME_COUNTERS, NO_SUCH_NAME_PER_HOUR_THRESHOLD, INFECTION_SCANNING_THRESHOLD,
                           PORT_SCANNING_THRESHOLD, POTENTIAL_INFECTION_PORTS, read_config, REGULAR_SENSOR_SLEEP_TIME,
                           SNAP_LEN, SUSPICIOUS_CONTENT_TYPES, SUSPICIOUS_DIRECT_DOWNLOAD_EXTENSIONS,
                           SUSPICIOUS_DIRECT_IP_URL_REGEX, SUSPICIOUS_DOMAIN_CONSONANT_THRESHOLD,
                           SUSPICIOUS_DOMAIN_ENTROPY_THRESHOLD, SUSPICIOUS_DOMAIN_LENGTH_THRESHOLD,
                           SUSPICIOUS_HTTP_PATH_REGEXES, SUSPICIOUS_HTTP_REQUEST_PRE_CONDITION,
                           SUSPICIOUS_HTTP_REQUEST_REGEXES, SUSPICIOUS_HTTP_REQUEST_FORCE_ENCODE_CHARS,
                           SUSPICIOUS_PROXY_PROBE_PRE_CONDITION, SUSPICIOUS_UA_REGEX, VALID_DNS_NAME_REGEX, trails,
                           VERSION, WEB_SCANNING_THRESHOLD, WHITELIST, WHITELIST_DIRECT_DOWNLOAD_KEYWORDS,
                           WHITELIST_LONG_DOMAIN_NAME_KEYWORDS, WHITELIST_HTTP_REQUEST_PATHS, WHITELIST_UA_REGEX)
from core.update import update_ipcat, update_trails
from thirdparty import six
from thirdparty.six.moves import urllib as _urllib

warnings.filterwarnings(action="ignore", category=DeprecationWarning)

# Global variables
_buffer = None
_caps = []
_connect_sec = 0
_connect_src_dst = {}
_connect_src_details = {}
_path_src_dst = {}
_path_src_dst_details = {}
_count = 0
_locks = AttribDict()
_multiprocessing = None
_n = None
_result_cache = LRUDict(MAX_CACHE_ENTRIES)
_local_cache = LRUDict(MAX_CACHE_ENTRIES)
_last_syn = None
_last_logged_syn = None
_last_udp = None
_last_logged_udp = None
_done_count = 0
_done_lock = threading.Lock()
_subdomains = {}
_subdomains_sec = None
_dns_exhausted_domains = set()

class _set(set):
    pass

try:
    import pcapy
except ImportError:
    if IS_WIN:
        sys.exit("[!] please install 'WinPcap' (e.g. 'http://www.winpcap.org/install/') and Pcapy (e.g. 'https://breakingcode.wordpress.com/?s=pcapy')")
    else:
        sys.exit(f"[!] please install 'Pcapy' (e.g. 'sudo pip{3 if six.PY3 else 2} install pcapy-ng')")

def _check_domain_member(query, domains):
    parts = query.lower().split('.')
    return any('.'.join(parts[i:]) in domains for i in range(len(parts)))

def _check_domain_whitelisted(query):
    cache_key = (CACHE_TYPE.DOMAIN_WHITELISTED, query)
    result = _result_cache.get(cache_key)

    if result is None:
        result = _check_domain_member(re.split(r"(?i)[^A-Z0-9._-]", query or "")[0], WHITELIST)
        _result_cache[cache_key] = result

    return result

def _check_domain(query, sec, usec, src_ip, src_port, dst_ip, dst_port, proto, packet=None):
    if query:
        query = query.lower().split(':')[0]
    if query.replace('.', "").isdigit():
        return

    if _result_cache.get((CACHE_TYPE.DOMAIN, query)) is False:
        return

    result = False
    if re.search(VALID_DNS_NAME_REGEX, query) and not _check_domain_whitelisted(query):
        parts = query.split('.')

        if query.endswith(".ip-adress.com"):
            trail = f"{'.'.join(parts[:-2])}(.ip-adress.com)"
            if parts[-3] in trails:
                result = True
                log_event((sec, usec, src_ip, src_port, dst_ip, dst_port, proto, TRAIL.DNS, trail, trails[parts[-3]][0], trails[parts[-3]][1]), packet)

        if not result:
            for i in range(len(parts)):
                domain = '.'.join(parts[i:])
                if domain in trails:
                    trail = domain if domain == query else f"({query[:-len(domain)-1]}){domain}"
                    if not (re.search(r"(?i)\A([rd]?ns|nf|mx|nic)\d*\.", query) and any(_ in trails[domain][0] for _ in ("suspicious", "sinkhole"))):
                        if not ((query == trail or parts[0] == "www") and any(_ in trails[domain][0] for _ in ("dynamic", "free web"))):
                            result = True
                            log_event((sec, usec, src_ip, src_port, dst_ip, dst_port, proto, TRAIL.DNS, trail, trails[domain][0], trails[domain][1]), packet)
                            break

        if not result and config.USE_HEURISTICS:
            if len(parts[0]) > SUSPICIOUS_DOMAIN_LENGTH_THRESHOLD and '-' not in parts[0]:
                trail = f"({'.'.join(parts[:-2])}).{'.'.join(parts[-2:])}" if len(parts) > 2 else f"({parts[0]}).{parts[1]}" if len(parts) == 2 else query
                if trail and not any(_ in trail for _ in WHITELIST_LONG_DOMAIN_NAME_KEYWORDS):
                    result = True
                    log_event((sec, usec, src_ip, src_port, dst_ip, dst_port, proto, TRAIL.DNS, trail, "long domain (suspicious)", "(heuristic)"), packet)

        if not result and trails._regex:
            match = re.search(trails._regex, query)
            if match:
                group, trail = next((k, v) for k, v in match.groupdict().items() if v)
                candidate = trails._regex.split("(?P<")[int(group[1:]) + 1].split('>', 1)[-1].rstrip('|')[:-1]
                if candidate in trails:
                    result = True
                    trail = match.group(0).replace(".)", ").")
                    prefix, suffix = query[:match.start()], query[match.end():]
                    trail = f"({prefix}){trail}" if prefix else trail
                    trail = f"{trail}({suffix})" if suffix else trail
                    log_event((sec, usec, src_ip, src_port, dst_ip, dst_port, proto, TRAIL.DNS, trail, trails[candidate][0], trails[candidate][1]), packet)

        if not result and ".onion." in query:
            trail = re.sub(r"(\.onion)(\..*)", r"\1(\2)", query)
            if trail.split('(')[0] in trails:
                result = True
                log_event((sec, usec, src_ip, src_port, dst_ip, dst_port, proto, TRAIL.DNS, trail, trails[trail.split('(')[0]][0], trails[trail.split('(')[0]][1]), packet)

    if not result:
        _result_cache[(CACHE_TYPE.DOMAIN, query)] = False

def _get_local_prefix():
    sources = set(_.split('~')[0] for _ in _connect_src_dst.keys())
    candidates = [re.sub(r"\d+\.\d+\Z", "", _) for _ in sources]
    result = max(((candidates.count(_), _) for _ in set(candidates)), default=(0, ""))[1]
    if result:
        _result_cache[(CACHE_TYPE.LOCAL_PREFIX, None)] = result

def _process_packet(packet):
    if packet:
        try:
            eth_header = struct.unpack("!6s6sH", packet[:14])
            if eth_header[2] == 0x0800:
                ip_header = struct.unpack("!BBHHHBBH4s4s", packet[14:34])
                ip_proto = ip_header[6]

                src_ip = socket.inet_ntoa(ip_header[8])
                dst_ip = socket.inet_ntoa(ip_header[9])

                if ip_proto == PROTO.TCP:
                    tcp_header = packet[34:54]
                    tcp_header = struct.unpack("!HHLLBBHHH", tcp_header)
                    src_port, dst_port = tcp_header[0], tcp_header[1]
                    data = packet[54:]
                elif ip_proto == PROTO.UDP:
                    udp_header = packet[34:42]
                    udp_header = struct.unpack("!HHHH", udp_header)
                    src_port, dst_port = udp_header[0], udp_header[1]
                    data = packet[42:]
                else:
                    return

                sec, usec = struct.unpack("!LL", packet[:8])
                _check_domain(data.decode('utf-8', 'ignore'), sec, usec, src_ip, src_port, dst_ip, dst_port, ip_proto, packet)
        except Exception as e:
            log_error(f"Exception in _process_packet: {e}")

def main():
    read_config()
    create_log_directory()
    trails.clear()
    load_trails()
    pcapy.findalldevs()

    device = config.DEVICE or pcapy.findalldevs()[0]
    cap = pcapy.open_live(device, SNAP_LEN, True, 1000)
    
    _get_local_prefix()
    
    while True:
        header, packet = cap.next()
        _process_packet(packet)

if __name__ == "__main__":
    main()
